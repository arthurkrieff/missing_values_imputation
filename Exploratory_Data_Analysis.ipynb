{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "from pyspark.sql import SparkSession\n",
    "from azure.storage.blob import ContainerClient\n",
    "from blob_credentials import facts_sas_token, facts_container, workspace_sas_token, workspace_container\n",
    "from functions.import_data import import_datasets\n",
    "from functions.utils import find_first_value\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import StrVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing R modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import R's utility package\n",
    "utils = rpackages.importr('utils')\n",
    "\n",
    "# select a mirror for R packages\n",
    "utils.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
    "\n",
    "# R package names\n",
    "packnames = ('RBtest')\n",
    "\n",
    "# Selectively install what needs to be install.\n",
    "# We are fancy, just because we can.\n",
    "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
    "if len(names_to_install) > 0:\n",
    "    utils.install_packages(StrVector(names_to_install))\n",
    "    \n",
    "RBtest = importr('RBtest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myname = \"marc-samvath-philippe.vigneron\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(f\"Test-{myname}\") \\\n",
    "    .config(\"spark.executor.instance\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\",\"512m\") \\\n",
    "    .config('spark.jars.packages',\"org.apache.hadoop:hadoop-azure:3.1.1\") \\\n",
    "    .config(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\") \\\n",
    "    .config(\"fs.wasbs.impl\",\"org.apache.hadoop.fs.azure.NativeAzureFileSystem\") \\\n",
    "    .config(f\"fs.azure.sas.{facts_container}.hecdf.blob.core.windows.net\", facts_sas_token) \\\n",
    "    .config(f\"fs.azure.sas.{workspace_container}.hecdf.blob.core.windows.net\", workspace_sas_token) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_challenge = import_datasets()[0]\n",
    "final_mapping = import_datasets()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing is to see how many columns exist for each asset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"Type\", data=final_mapping)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Number of columns for each Asset type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each asset type, we check the missing values as a time series - to see where the time series begins(which year) or for that matter how many missing values occur in a row and to assess the sparsity of each row as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset_challenge[[str(i) for i in range(59)]])\n",
    "plt.title('Missing Values Bonds',fontsize=20)\n",
    "plt.xlabel('Asset Columns',fontsize=18)\n",
    "plt.ylabel('Time series values',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the time series actually start very late. This means that there is a possibility we need to use other column values in the same row to impute missing values for these columns, as there might not be enough values in the time series itself, alone, to impute the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset_challenge[[str(i) for i in range(59,100)]])\n",
    "plt.title('Missing Values CDS',fontsize=20)\n",
    "plt.xlabel('Asset Columns',fontsize=18)\n",
    "plt.ylabel('Time series values',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CDS asset, we notice that almost all columns are populated from the beginning. In addition there seems to be a balance between number of columns that have many missing values vs those that have a few missing values. However, this is a sample of the total number of columns and not all - so the results are not completely conclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commodities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset_challenge[[str(i) for i in range(735,815)]])\n",
    "plt.title('Missing Values COMMO_CURVE_FO',fontsize=20)\n",
    "plt.xlabel('Asset Columns',fontsize=18)\n",
    "plt.ylabel('Time series values',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some time series starting from the beginning and others starting from a later year, this asset type too could benefit from correlations with other columns within the asset type and outside of it. Definitely, 'removing' the missing values or imputing with a constant, is not a very efficient option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foreign Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset_challenge[[str(i) for i in range(815,925)]])\n",
    "plt.title('Missing Values FX Rate',fontsize=20)\n",
    "plt.xlabel('Asset Columns',fontsize=18)\n",
    "plt.ylabel('Time series values',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this asset type there seem to be many columns that have a lot of rows with consecutive missing values. This might impact the algorithm chosen for imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset_challenge[[str(i) for i in range(926,1000)]])\n",
    "plt.title('Missing Values Stocks',fontsize=20)\n",
    "plt.xlabel('Asset Columns',fontsize=18)\n",
    "plt.ylabel('Time series values',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocks, too, as other asset types shows high sparsity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foreign Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset_challenge[[str(i) for i in range(1253,1300)]])\n",
    "plt.title('Missing Values FX Rate',fontsize=20)\n",
    "plt.xlabel('Asset Columns',fontsize=18)\n",
    "plt.ylabel('Time series values',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easily visible that a few columns have fewer nan values as compared to others. There are also a few columns that have chunks of missing values together - rows with consecutive missing nans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap for correlation of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(dataset_challenge[['0','1','2','3','4','5','6','7','8','9','10']].corr(),annot=True)\n",
    "plt.title('Heatmap for correlation',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is quite evident, there is a lot of correlation (positive or negative) observed between different columns which can be exploited for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Successive NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_max_successive_nan(values):\n",
    "    \"\"\"\n",
    "    How many successive nans in max ?\n",
    "    Params:\n",
    "        - values (np.array) : must be ordered by time\n",
    "    Output: integer\n",
    "    \"\"\"\n",
    "    max_total = 0\n",
    "    res = 0\n",
    "    \n",
    "    for val in values:\n",
    "        if np.isnan(val):\n",
    "            res += 1\n",
    "        elif res!=0:\n",
    "            total = res\n",
    "            res = 0\n",
    "            if total > max_total:\n",
    "                max_total = total\n",
    "    \n",
    "    return max_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather the maximum successive nan values for each column in a dictionary\n",
    "max_successive_nans = dict()\n",
    "for col in dataset_challenge.columns[1:]:\n",
    "    first_val = find_first_value(dataset_challenge.loc[:,col].to_numpy())\n",
    "    if first_val != 'NaN':\n",
    "        values = dataset_challenge.loc[first_val:,col].to_numpy()\n",
    "    else:\n",
    "        values = dataset_challenge.loc[:,col].to_numpy()\n",
    "    max_successive_nans[col] = count_max_successive_nan(values)\n",
    "\n",
    "# Sorted dictionary\n",
    "{k: v for k, v in sorted(max_successive_nans.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "#Keeping only greater than 500 successive Nans \n",
    "data = [(k,v) for k,v in max_successive_nans.items() if v]\n",
    "df_max_nans = pd.DataFrame.from_records(data, columns=['keys', 'values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_nans.hist(bins=10)\n",
    "plt.title('Successive Nan values',fontsize=10)\n",
    "plt.xlabel('Columns',fontsize=10)\n",
    "plt.ylabel('Number of max successive nan values',fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the columns have 2 successive nan values at maximum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas to r dataset converter\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_dataset_challenge = ro.conversion.py2rpy(dataset_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collating the test results to check which columns are MCAR, MAR or not missing.\n",
    "\n",
    "first_rbtest = RBtest.RBtest(r_dataset_challenge)\n",
    "test_results = np.asarray(first_rbtest)[2].astype(int).astype(str)\n",
    "test_results[test_results == '-1'] = 'Not Missing'\n",
    "test_results[test_results == '0'] = 'MCAR'\n",
    "test_results[test_results == '1'] = 'MAR'\n",
    "test_results = test_results.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plotting the missing values MCAR, MAR or Not missing\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "ax = sns.countplot(test_results)\n",
    "ax.set_title('Missing Value Types Count', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_ylabel(\"Count\",fontsize=15)\n",
    "\n",
    "for p in ax.patches:\n",
    "    x=p.get_bbox().get_points()[:,0]\n",
    "    y=p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate('{:.1f}%'.format(100.*y/len(test_results)), (x.mean(), y), \n",
    "            ha='center', va='bottom', fontsize=15) # set the alignment of the text\n",
    "\n",
    "plt.savefig('Missing_Values.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the test was conducted to see whether data was missing completely at random, missing at random or not missing. According to the plot, most of the data is missing completely at random which opens up various possibilities for imputation and does not restrict us to dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a different dataset for each asset type\n",
    "bond = dataset_challenge.iloc[:,0:58]\n",
    "cds = dataset_challenge.iloc[:,59:733]\n",
    "commodities = dataset_challenge.iloc[:,734:814]\n",
    "fxrate = dataset_challenge.iloc[:,815:925]\n",
    "stock = dataset_challenge.iloc[:,926:1252]\n",
    "yieldc = dataset_challenge.iloc[:,1253:1503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Percentage of missing values by asset type\n",
    "missing_asset_type = []\n",
    "missing_asset_type.append(bond.isna().sum().sum()/(58*2851))\n",
    "missing_asset_type.append(cds.isna().sum().sum()/((733-59)*2851))\n",
    "missing_asset_type.append(commodities.isna().sum().sum()/((814-734)*2851))\n",
    "missing_asset_type.append(fxrate.isna().sum().sum()/((925-815)*2851))\n",
    "missing_asset_type.append(stock.isna().sum().sum()/((1252-926)*2851))\n",
    "missing_asset_type.append(yieldc.isna().sum().sum()/((1503-1253)*2851))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Percentage of missing values by total columns\n",
    "missing_total = []\n",
    "missing_total.append(bond.isna().sum().sum()/(1504*2851))\n",
    "missing_total.append(cds.isna().sum().sum()/(1504*2851))\n",
    "missing_total.append(commodities.isna().sum().sum()/(1504*2851))\n",
    "missing_total.append(fxrate.isna().sum().sum()/(1504*2851))\n",
    "missing_total.append(stock.isna().sum().sum()/(1504*2851))\n",
    "missing_total.append(yieldc.isna().sum().sum()/(1504*2851))\n",
    "xlabels = ['Bond','CDS','commodities','fxrate','stock','yieldc']\n",
    "x = np.arange(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot of the percentage of missing values\n",
    "ax = plt.subplot(111)\n",
    "w = 0.3\n",
    "asset = ax.bar(x-w, missing_asset_type, width=w, color='b', align='center')\n",
    "total = ax.bar(x, missing_total, width=w, color='r', align='center')\n",
    "ax.autoscale(tight=True)\n",
    "plt.xticks(ticks=x,labels=xlabels)\n",
    "plt.yticks([0.1,0.2,0.3,0.4,0.5])\n",
    "plt.legend([asset, total],['%age missing by asset', '%age missing total'])\n",
    "plt.title('Percentage of missing values')\n",
    "plt.xlabel('Asset type')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above is a plot of the percentage of missing values by asset to the percentage of missing values by total number of values. Bonds has the maximum number of missing values by asset and that is perhaps due to the fact that as seen earlier, many of the time series start at a much later year as compared to the time series of other assets.\n",
    "\n",
    "- In addition, CDS has the highest percentage of missing values by all values, and that is very much credited to the fact that it has the most number of columns as compared to the other assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of percentage of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_missing_proportions(data: pd.DataFrame) -> list:\n",
    "    '''\n",
    "    input: a dataframe\n",
    "    output: List\n",
    "    Description: Creates a list with proportions of missing values\n",
    "    '''\n",
    "    props=[]\n",
    "    for col in data.columns:\n",
    "        series=data[col]\n",
    "        first_valid_index=series.first_valid_index()\n",
    "        ts=series[first_valid_index:]\n",
    "        length=len(ts)\n",
    "        nulls=ts.isnull().sum()\n",
    "        props.append(nulls/length)\n",
    "    return props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return a list with proportion of missing values\n",
    "props = ts_missing_proportions(dataset_challenge.drop('Date',axis=1))\n",
    "##Distribution plot\n",
    "sns.distplot(props,kde=False,norm_hist=False)\n",
    "sns.despine(left=True, bottom=True, right=True)\n",
    "plt.title('Distribution of percentage of missing values')\n",
    "plt.ylabel('Number of columns')\n",
    "plt.xlabel('Percentage of missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 140 assets that have nearly 6% of the data missing. Most of the columns have nearly 4-6% of data missing.\n",
    "- < 100 assets for more than 10% data missing. However, nearly 50 assets have 0-1% missing values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
