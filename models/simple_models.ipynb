{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.metrics import nrmse_adjusted\n",
    "from functions.utils import to_NAN, find_first_value\n",
    "from functions.import_data import import_datasets\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from azure.storage.blob import ContainerClient\n",
    "from blob_credentials import facts_sas_token, facts_container, workspace_sas_token, workspace_container\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2\n",
    "import impyute\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_quadraticInterpolation(df):\n",
    "    \"\"\"\n",
    "    Function that Interpolates missing values\n",
    "    Input:\n",
    "        - df: pd.DataFrame with NaNs\n",
    "    Output:\n",
    "        - pd.DataFrame  \n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    for col in tqdm(df.columns):\n",
    "        x = df.loc[:, col].dropna().index.values\n",
    "        y = df.loc[:, col].dropna().values\n",
    "        first_val = find_first_value(df.loc[:, col].values)\n",
    "        if first_val == 'NaN':\n",
    "            continue\n",
    "        else:\n",
    "            all_x = df.loc[first_val:, col].index.values\n",
    "            f = interp1d(x, y, kind='quadratic', fill_value='extrapolate')\n",
    "            df_imputed.loc[first_val:, col] = f(all_x)\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myname = \"marc-samvath-philippe.vigneron\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(f\"Test-{myname}\") \\\n",
    "    .config(\"spark.executor.instance\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\",\"512m\") \\\n",
    "    .config('spark.jars.packages',\"org.apache.hadoop:hadoop-azure:3.1.1\") \\\n",
    "    .config(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\") \\\n",
    "    .config(\"fs.wasbs.impl\",\"org.apache.hadoop.fs.azure.NativeAzureFileSystem\") \\\n",
    "    .config(f\"fs.azure.sas.{facts_container}.hecdf.blob.core.windows.net\", facts_sas_token) \\\n",
    "    .config(f\"fs.azure.sas.{workspace_container}.hecdf.blob.core.windows.net\", workspace_sas_token) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "dataset_challenge_gbm = spark.read.parquet(f'wasbs://{workspace_container}@hecdf.blob.core.windows.net/{myname}/generated_data_gbm.parquet').toPandas()\n",
    "dataset_challenge_kde = spark.read.parquet(f'wasbs://{workspace_container}@hecdf.blob.core.windows.net/{myname}/generated_data_kde.parquet').toPandas()\n",
    "dataset_challenge = import_datasets()[0]\n",
    "dataset_challenge.drop(columns=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting the values to nan\n",
    "dataset_challenge_gbm_nan = to_NAN(dataset_challenge_gbm, dataset_challenge)\n",
    "dataset_challenge_kde_nan = to_NAN(dataset_challenge_kde, dataset_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Observation Carried Forward (LOCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_locf = dataset_challenge_kde_nan.fillna(method='ffill')\n",
    "gbm_locf = dataset_challenge_gbm_nan.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_kde = nrmse_adjusted(dataset_challenge_kde.values, \n",
    "                             kde_locf.values,\n",
    "                             dataset_challenge_kde_nan.values)\n",
    "nrmses_kde = np.nanmean(np.array(list(i[0] for i in results_kde.values())))\n",
    "print(\"KDE NRMSE LOCF : %f\" % nrmses_kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbm = nrmse_adjusted(dataset_challenge_gbm.values, \n",
    "                             gbm_locf.values,\n",
    "                             dataset_challenge_gbm_nan.values)\n",
    "nrmses_gbm = np.nanmean(np.array(list(i[0] for i in results_gbm.values())))\n",
    "print(\"GBM  NRMSE LOCF: %f\" % nrmses_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_interpolation = impute_quadraticInterpolation(dataset_challenge_kde_nan)\n",
    "gbm_interpolation = impute_quadraticInterpolation(dataset_challenge_gbm_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_kde = nrmse_adjusted(dataset_challenge_kde.values, \n",
    "                             kde_interpolation.values,\n",
    "                             dataset_challenge_kde_nan.values)\n",
    "nrmses_kde = np.nanmean(np.array(list(i[0] for i in results_kde.values())))\n",
    "print(\"KDE NRMSE LOCF : %f\" % nrmses_kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbm = nrmse_adjusted(dataset_challenge_gbm.values, \n",
    "                             gbm_interpolation.values,\n",
    "                             dataset_challenge_gbm_nan.values)\n",
    "nrmses_gbm = np.nanmean(np.array(list(i[0] for i in results_gbm.values())))\n",
    "print(\"GBM  NRMSE LOCF: %f\" % nrmses_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to R datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the R package work, we convert the the dataframes into R datasets and import the neccessary R package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_dataset_challenge = ro.conversion.py2rpy(dataset_challenge)\n",
    "    r_dataset_challenge_gbm = ro.conversion.py2rpy(dataset_challenge_gbm)\n",
    "    r_dataset_challenge_kde = ro.conversion.py2rpy(dataset_challenge_kde)\n",
    "    r_dataset_challenge_gbm_nan = ro.conversion.py2rpy(dataset_challenge_gbm_nan)\n",
    "    r_dataset_challenge_kde_nan = ro.conversion.py2rpy(dataset_challenge_kde_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import R's utility package\n",
    "utils = rpackages.importr('utils')\n",
    "\n",
    "# select a mirror for R packages\n",
    "utils.chooseCRANmirror(ind=1) # select the first mirror in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "utils.install_packages(\"imputeTS\")\n",
    "imputeTS = importr('imputeTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: it takes several hours to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dataset_challenge_gbm_imputed = imputeTS.na_ma(r_dataset_challenge_gbm_nan)\n",
    "r_dataset_challenge_kde_imputed = imputeTS.na_ma(r_dataset_challenge_kde_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    dataset_challenge_gbm_imputed = ro.conversion.rpy2py(r_dataset_challenge_gbm_imputed)\n",
    "    dataset_challenge_kde_imputed = ro.conversion.rpy2py(r_dataset_challenge_kde_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbm = nrmse_adjusted(dataset_challenge_gbm.values, \n",
    "                             dataset_challenge_gbm_imputed.values,\n",
    "                             dataset_challenge_gbm_nan.values)\n",
    "\n",
    "nrmses_gbm = np.nanmean(np.array(list(i[0] for i in results_gbm.values())))\n",
    "print(\"GBM Weighted Moving Average Mean NRMSE: %f\" % nrmses_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_kde = nrmse_adjusted(dataset_challenge_kde.values, \n",
    "                             dataset_challenge_kde_imputed.values,\n",
    "                             dataset_challenge_kde_nan.values)\n",
    "nrmses_kde = np.nanmean(np.array(list(i[0] for i in results_kde.values())))\n",
    "print(\"KDE Weighted Moving Average Mean NRMSE: %f\" % nrmses_kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
